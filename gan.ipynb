{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose({\n",
    "    torchvision.transforms.Resize((256, 256)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    # transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:/Users/ohhara/generative_model/generative_model/dataset/Tufts Dental Database/Radiographs\"\n",
    "image_list = os.listdir(root_path)\n",
    "with open(\"C:/Users/ohhara/generative_model/generative_model/dataset/Tufts Dental Database/Radiographs/index.txt\", \"w\") as f:\n",
    "   for image_name in image_list:\n",
    "      f.write(image_name+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの準備\n",
    "class TuftsDataset(Dataset):\n",
    "    def __init__(self, root_path, transform=None, input_size=256):\n",
    "        self.root_path = root_path\n",
    "        self.transform = transform\n",
    "        self.len = len(os.listdir(root_path))\n",
    "         \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        with open(\"C:/Users/ohhara/generative_model/generative_model/dataset/Tufts Dental Database/index.txt\", \"r\") as f:\n",
    "            image_name = f.readlines()[index].strip()\n",
    "        image_path = os.path.join(self.root_path, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = TuftsDataset(root_path=\"C:/Users/ohhara/generative_model/generative_model/dataset/Tufts Dental Database/Radiographs\", transform=transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"学習プロセスの表示の為の関数\"\"\"\n",
    "def display_process(hist, G, image_frame_dim, sample_z, fix=True):\n",
    "    plt.gcf().clear()\n",
    "\n",
    "    fig = plt.figure(figsize=(24, 15))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    x = range(len(hist[\"D_loss\"]))\n",
    "\n",
    "    y1 = hist[\"D_loss\"]\n",
    "    y2 = hist[\"G_loss\"]\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    ax1.plot(x, y1, label=\"D_loss\")\n",
    "    ax1.plot(x, y2, label=\"G_loss\")\n",
    "\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "\n",
    "    samples = G(sample_z)\n",
    "    samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "    samples = (samples + 1) / 2\n",
    "\n",
    "    for i in range(image_frame_dim*image_frame_dim):\n",
    "        ax = fig.add_subplot(image_frame_dim, image_frame_dim*2, (int(i/image_frame_dim)+1)*image_frame_dim+i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(samples[i])\n",
    "    else:\n",
    "        ax.imshow(samples[i][:,:,0], cmap=\"gray\")\n",
    "        \n",
    "\n",
    "    ax1.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みの初期化関数の定義\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generatorの作成\"\"\"\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, output_dim=1, input_size=256):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128*(self.input_size//16)**2),\n",
    "            nn.BatchNorm1d(128*(self.input_size//16)**2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, self.output_dim, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "        def forward(self, input):\n",
    "            x = self.fc(input)\n",
    "            x = x.view(-1, 128, self.input_size//16, self.input_size//16)\n",
    "            x = self.deconv(x)\n",
    "            return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Discriminatorの作成\"\"\"\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=256, sig_out=True):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.input_size = input_size\n",
    "        self.output_dim = output_dim\n",
    "        self.sig_out = sig_out\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*(self.input_size//4)**2, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 1),\n",
    "            \n",
    "        )\n",
    "        if self.sig_out:\n",
    "            self.fc.add_module(\"sigmoid\",nn.Sigmoid())\n",
    "        initialize_weights(self)\n",
    "        \n",
    "        def forward(self, input):\n",
    "            x = self.conv(input)\n",
    "            x = x.view(-1, 128*(self.input_size//4)**2)\n",
    "            x = self.fc(x)\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GANの学習\"\"\"\n",
    "class GAN:\n",
    "    def __init__(self, epoch=500):\n",
    "        self.epochs = epoch\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.sample_num = 16\n",
    "        self.batch_size = 32\n",
    "        self.input_size = 256   \n",
    "        self.z_dim = 64\n",
    "        self.lrG = 0.0002\n",
    "        self.lrD = 0.0002\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.999\n",
    "\n",
    "        # データローダ\n",
    "        self.data_loader = DataLoader(mydataset, self.input_size, self.batch_size)\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # モデルの初期化\n",
    "        self.G = Generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size).to(self.device)\n",
    "        self.D = Discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size).to(self.device)\n",
    "        self.G_optimizer = torch.optim.Adam(self.G.parameters(), lr=self.lrG, betas=(self.beta1, self.beta2))\n",
    "        self.D_optimizer = torch.optim.Adam(self.D.parameters(), lr=self.lrD, betas=(self.beta1, self.beta2))\n",
    "\n",
    "        # cudaに乗っける\n",
    "        self.G.to(self.device)\n",
    "        self.D.to(self.device)\n",
    "        self.BCE_loss = nn.BCELoss().to(self.device)\n",
    "\n",
    "        self.sample_z = torch.randn(self.sample_num, self.z_dim).to(self.device)\n",
    "        \n",
    "    def train(self):\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "\n",
    "        self.y_real, self.y_fake = torch.ones(self.batch_size, 1).to(self.device), torch.zeros(self.batch_size, 1).to(self.device)\n",
    "        \n",
    "        # 訓練モードにする\n",
    "        self.D.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            for iter, x_ in enumerate(self.data_loader): # (batch_size, 3, 256, 256)\n",
    "                if iter == self.data_loader.__len__() // self.batch_size:\n",
    "                    break\n",
    "                # zをサンプリング\n",
    "                x_ = x_.to(self.device)\n",
    "                z = torch.randn(self.batch_size, self.z_dim).to(self.device)\n",
    "\n",
    "                # Discriminatorの更新\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_)\n",
    "                D_real_loss = self.BCE_loss(D_real, self.y_real)\n",
    "\n",
    "                G = self.G(z)\n",
    "                D_fake = self.D(G)\n",
    "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake)\n",
    "\n",
    "                # D_lossの計算\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.train_hist[\"D_loss\"].append(D_loss.item())\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                # Generatorの更新\n",
    "                self.G_optimizer.zero_grad()\n",
    "                G = self.G(z)\n",
    "                D_fake = self.D(G)\n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real)\n",
    "                self.train_hist[\"G_loss\"].append(G_loss.item())\n",
    "                D_fake = self.D(G)\n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real)\n",
    "                self.train_hist[\"G_loss\"].append(G_loss.item())\n",
    "\n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "\n",
    "\n",
    "                # ディスプレイ\n",
    "                if ((iter + 1) %10 == 0):\n",
    "                    with torch.no_grad():\n",
    "                        tot_num_samples = min(self.sample_num, self.batch_size)\n",
    "                        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
    "                        display_process(self.train_hist, self.G, image_frame_dim, self.sample_z)\n",
    "                        display.clear_output(wait=True)\n",
    "                        display(plt.gcf())\n",
    "                        plt.close()\n",
    "\n",
    "        plt.close()\n",
    "        print(\"Training complete\")\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN()\n",
    "gan.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([8, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for iter, x in enumerate(DataLoader(mydataset, batch_size=32, shuffle=True)):\n",
    "    print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
